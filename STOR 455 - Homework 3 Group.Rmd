---
title: 'STOR 455 Homework #3'
subtitle: 40 points - Due 9/28 at 11:59pm
output:
  pdf_document: default
  html_document:
    df_print: paged
---
```{r}
library(readr)
Ames_Train = read.csv("AmesTrain13.csv")
```

__Directions:__ You will be assigned to a group of three to four students for this assignment. Parts 1, 2, & 5 should be submitted individually to Gradescope by each student in your group. Parts 3 & 4 should be submitted as a group to Gradescope. There are separate places to submit the individual and group portions of the assignment. 
    
__Situation:__ Can we predict the selling price of a house in Ames, Iowa based on recorded features of the house? That is your task for this assignment. Each group will have a dataset with information on forty potential predictors and the selling price (in $1,000’s) for a sample of homes. The data set for your group is in AmesTrain??.csv (where ?? corresponds to your group number) and can be found in the AmesTrain zipped file under class 14 in Sakai. A separate file identifies the variables in the Ames Housing data and explains some of the coding.

### Part 1. Build an initial “basic” model ###    
Your basic model can use any of the quantitative variables in the dataset but should NOT use the categorical variables, transformations, or interactions (we’ll discuss these in class soon) – those will come in a later assignment. Use your data to select a set of predictors to include in your model. Keep track of the process you use and decisions you make to arrive at an initial set of predictors. Your report should include a summary of this process. You don’t need to show all the output for every model you consider, but you should give a clear description of the path you took and the criteria that you used to compare competing models. Also, use at least two model selection methods to find a model (e.g. don’t just check all subsets, although it will work well here, this method will fail in future assignments).  

```{r}
library(leaps)
library(corrplot)
library(car)
source("https://raw.githubusercontent.com/JA-McLean/STOR455/master/scripts/ShowSubsets.R")
subsets = regsubsets(Price~LotArea + LotFrontage + FullBath + HalfBath + YearRemodel + BasementSF + GroundSF + BasementFBath + BasementHBath + TotalRooms + Fireplaces + GarageSF + WoodDeckSF, data = Ames_Train)
#summary(subsets)
ShowSubsets(subsets)
print.data.frame(ShowSubsets(subsets))
```

When testing for best parameters, I omitted any variables that had the potential to overlap with other included parameters, as well as any categorical variables that were non-numeric, as well as any ranking system numeric variables as those are also inherently categorical.

Based on the output of the All Subsets approach, the model with the lowest Cp value contains LotArea, YearRemodel, BasementSF, GroundSF, BasementFBath, TotalRooms, Fireplaces, and GarageSF. 

```{r}
Full = lm(Price~LotArea + LotFrontage + FullBath + HalfBath + YearRemodel + BasementSF + GroundSF + BasementFBath + BasementHBath + TotalRooms + Fireplaces + GarageSF + WoodDeckSF, Ames_Train)
MSE = (summary(Full)$sigma)^2
none = lm(Price~1, Ames_Train)
step(none, scope=list(upper=Full), scale = MSE, direction = "forward", trace = TRUE)
```

The best model drawn from Forward Selection includes HalfBath, LotFrontage + FullBath. 

```{r}
mod_AS = lm(Price~LotArea+YearRemodel+BasementSF+GroundSF+BasementFBath+TotalRooms+Fireplaces+GarageSF, Ames_Train)
mod_FS = lm(Price~HalfBath+LotFrontage+FullBath, Ames_Train)
summary(mod_AS)
summary(mod_FS)
#Ho: Bi = 0
#Ha: Bi /= 0
# where Bi is any given predictor
```

Since in the p-values of the predictors are all lower than .05, we have statistically significant evidence to say that the coefficient of all the included variables is not zero. 

```{r}
vif(mod_AS)
vif(mod_FS)
```

Based on the VIF values for both models, we do not need to be concerned about the influence of any of the parameters as their VIF score is less than 5.

Since the adjusted R^2 is largest for the first model, and both models do not have any predictors that need to removed, I will choose the first model moving forward for the analysis. Although the adjusted R^2 doesn't tell us whether the model is "good" or "bad" it does show what percentage of the variability in Price is determined by our predictors. Additionally, the f-statistic for mod_AS is better, contributing to the argument to use that one instead.
    
In addition to the commentary on model selection, include the following information for this initial choice of a model:

* the summary() output for your model
* comments on which (if any) of the predictors in the model are not significant at a 5% level
* comments on what the VIF values tell you about the individual predictors in your model
    
Do not consider the Order variable (that is just an observation number) as one of your predictors. Avoid predictors that are exactly related. For example, if GroundSF=FirstSF+SecondSF you will likely get trouble if you try to put all three in the same model. 
       
### Part 2. Residual analysis for your basic model ###    
Do a residual analysis for the model you chose in Part 1. Include any plots relevant to checking model conditions - with interpretations. Also check whether any of the data cases are unusual with respect to studentized residuals. Since there are a lot of data points don’t worry about the “mild” cases for studentized residuals, but indicate what specific criteria you are using to identify “unusual” points. 
   
Adjust your model (either the predictors included or data values that are used to fit it, but not yet using transformations) on the basis of your residual analysis – but don’t worry too much about trying to get all conditions “perfect”.  For example, don’t automatically just delete any points that might give large residuals! If you do refit something, be sure to document what changed and include the new summary() output.

```{r}
plot(mod_AS,1:2)
```
Conditions:
Linearity - based on the line in the fitted values vs residuals plot, the residuals appear to be well fit to the line
Zero Mean - based on the fitted values vs residuals plot, the line does not seem to be well centered at zero
Constant Variance - based on the fitted values vs residuals plot, the data appears to be clumped together and tends to demonstrate the "fan" tendency
Independence - based on the fitted values vs residuals plot, there does not appear to be a pattern to the residuals and they do seem relatively randomly scattered
Normality - based on the Normal QQ plot, the standardized residuals do not appear to fit the line of normality extremely well as their is right and left skew.

```{r}
indices = sort(abs(mod_AS$resid), decreasing=TRUE, index.return=TRUE)$ix[1:10]
rstudent(mod_AS)[indices]
```

Based on the studentized residuals there are at least ten points that are of concern as their value is greater than +- 3. These points can all be identified as "unusual" due to their abnormally large studentized residual values. I will remove the top four values as those are above a studentized residual value of 4  and see how that changes our model.
```{r}
newdata = Ames_Train[-c(180,242,495,587)]
mod_AS2 = lm(Price~LotArea+YearRemodel+BasementSF+GroundSF+BasementFBath+TotalRooms+Fireplaces+GarageSF, newdata)
plot(mod_AS2,1:2)
```

Having removed those four high studentized residual values, the conditions appear to be met relativley the same. That being said, I will continue using the original mod_AS.
    
### Part 3: Find a “fancier model”: ###    
    
In addition to the quantitative predictors from Part 1, you may now consider models with:     

* Transformations of predictors. You can include functions of quantitative predictors. Probably best to use the I() notation so you don’t need to create new columns when you run the predictions for the test data. For example:      lm(Price~LotArea+I(LotArea^2)+sqrt(LotArea)+log(LotArea),... 
* Transformations of the response. You might address curvature or skewness in residual plots by transforming the response prices with a function like log(Price ), sqrt(Price), Price^2, etc..  These should generally not need the I( ) notation to make these adjustments.
* Combinations of variables. This might include for example creating a new variable which would count the total bathrooms in the house in a single predictor.  

Do not haphazardly use transformation on predictors, but examine the relationships between the predictors and response to determine when a transformation would be warranted. Again use multiple model selection methods to determine a best model, but now with transformed variables are possible predictors in the model.


```{r}
Ames_Train$TotalSF = Ames_Train$GroundSF + Ames_Train$BasementSF + Ames_Train$GarageSF
newdata$TotalSF = Ames_Train$GroundSF + Ames_Train$BasementSF + Ames_Train$GarageSF
class(newdata$TotalSF)
plot(Price~LotArea+YearRemodel+TotalSF+BasementFBath+TotalRooms+Fireplaces, Ames_Train)
trans_mod = lm(Price~sqrt(LotArea)+YearRemodel+I(TotalSF^2)+BasementFBath+TotalRooms+Fireplaces, newdata)
plot(Price~sqrt(LotArea), Ames_Train)
summary(trans_mod)
```

```{r}
plot(trans_mod)
plot(mod_AS2)
```


__Discuss the process that you used to transform the predictors and/or response so that you could use this process in the future on a new data set.__

A transformation that could be deemed reasonable is combining GroundSF, BasementSF, and GarageSF as they are representative of the SF of the house and do not overlap already and all three predictors measure in the same units. Additionally, when looking at the standard Price vs LotArea plot, the data seem to be bunched up and there is not as much variance as we would like to see. That being said, we squared LotArea in hopes of increasing the variance.


### Part 4. Residual analysis for your fancier model ###    

Repeat the residual analysis from Part 2 on your new model constructed in Part 3. A residual analysis was likely (hopefully) part of your process for determining your "fancier" model. That does not need to be repeated here as long as you clearly discuss your process.

In comparison to the model residuals before and after the transformations, the original model 

### Part 5. Final model ###     

Suppose that you are interested in a house in Ames that has the characteristics listed below. Construct a 95% confidence interval for the mean price of such houses.

A 2 story 11 room home, built in 1987 and remodeled in 1999 on a 21540 sq. ft. lot with 328 feet of road frontage. Overall quality is good (7) and condition is average (5). The quality and condition of the exterior are both good (Gd) and it has a poured concrete foundation. There is an 757 sq. foot basement that has excellent height, but is completely unfinished and has no bath facilities. Heating comes from a gas air furnace that is in excellent condition and there is central air conditioning. The house has 2432 sq. ft. of living space above ground, 1485 on the first floor and 947 on the second, with 4 bedrooms, 2 full and one half baths, and 1 fireplace. The 2 car, built-in garage has 588 sq. ft. of space and is average (TA) for both quality and construction. The only porches or decks is a 205 sq. ft. open porch in the front. 

```{r}

```

